# Batch-Normalization-and-Dropout

Batch-Normalization and Dropout Concepts are explained with the help of code in this repository. They are analyzed by visualizing the 
performance of Deep Neural Network with and without these techniques. The dataset used in MNIST dataset.
The result obtained was that the loss was significantly reduced and thus, overfitting was also reduced.
